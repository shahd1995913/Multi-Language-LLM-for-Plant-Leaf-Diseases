{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1v6G1CJzz0CLyKWJmtobDujgobvUTyzRf",
      "authorship_tag": "ABX9TyOn/T7ECleHCDjaBN1mwP+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahd1995913/Multi-Language-LLM-for-Plant-Leaf-Diseases/blob/main/Multi_Language_LLM_for_disease_description.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1 Use Deep learning For train and test in Image Dataset"
      ],
      "metadata": {
        "id": "2TveMRHmTi7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvHzbgYFp8Ga",
        "outputId": "d460efa5-e85e-4fb4-afc1-313792c3ee5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.34.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.8.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "#1️⃣ Install the necessary libraries\n",
        "# =========================================\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install timm\n",
        "!pip install transformers\n",
        "!pip install scikit-learn\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install transformers accelerate sentencepiece\n",
        "!pip install transformers accelerate sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 1️⃣ Imports\n",
        "# =========================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# =========================================\n",
        "# 2️⃣ Setup Dataset\n",
        "# =========================================\n",
        "# Copy dataset to local tmp for speed\n",
        "src_dir = \"/content/drive/MyDrive/PALM Reserch/Palm Leaves Dataset\"\n",
        "data_dir = \"/tmp/palm_dataset\"\n",
        "if not os.path.exists(data_dir):\n",
        "    shutil.copytree(src_dir, data_dir)\n",
        "\n",
        "# Filter out empty folders\n",
        "valid_folders = [f for f in os.listdir(data_dir)\n",
        "                 if os.path.isdir(os.path.join(data_dir,f))\n",
        "                 and len(os.listdir(os.path.join(data_dir,f))) > 0]\n",
        "\n",
        "# Image transforms (smaller size = faster)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96,96)),  # smaller than 128x128 for speed\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],\n",
        "                         [0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "classes = dataset.classes\n",
        "print(\"✅ Classes Detected:\", classes)\n",
        "\n",
        "# =========================================\n",
        "# 3️⃣ Split dataset 70/20/10\n",
        "# =========================================\n",
        "total_len = len(dataset)\n",
        "train_len = int(0.7 * total_len)\n",
        "val_len = int(0.2 * total_len)\n",
        "test_len = total_len - train_len - val_len\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print(f\"Total images: {total_len} | Train: {len(train_dataset)} | Val: {len(val_dataset)} | Test: {len(test_dataset)}\")\n",
        "\n",
        "# =========================================\n",
        "# 4️⃣ Plot sample image from each class\n",
        "# =========================================\n",
        "# def imshow(img, title):\n",
        "#     img = img.numpy().transpose((1,2,0))\n",
        "#     img = img * np.array([0.229,0.224,0.225]) + np.array([0.485,0.456,0.406])\n",
        "#     img = np.clip(img, 0,1)\n",
        "#     plt.imshow(img)\n",
        "#     plt.title(title)\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "\n",
        "# for i, cls in enumerate(classes):\n",
        "#     idx = next(idx for idx, (_, label) in enumerate(dataset.samples) if label == i)\n",
        "#     img, _ = dataset[idx]\n",
        "#     imshow(img, cls)\n",
        "\n",
        "# =========================================\n",
        "# 5️⃣ Setup MobileNetV3 small\n",
        "# =========================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = models.mobilenet_v3_small(pretrained=True)\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, len(classes))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# =========================================\n",
        "# 6️⃣ Train function\n",
        "# =========================================\n",
        "def train_model(model, train_loader, val_loader, epochs=5):\n",
        "    best_val_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds, val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {avg_train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    print(\"Training complete. Best Val Acc:\", best_val_acc)\n",
        "\n",
        "# =========================================\n",
        "# 7️⃣ Train\n",
        "# =========================================\n",
        "train_model(model, train_loader, val_loader, epochs=5)\n",
        "\n",
        "# =========================================\n",
        "# 8️⃣ Evaluate on Test Set\n",
        "# =========================================\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "all_preds, all_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "prec = precision_score(all_labels, all_preds, average='weighted')\n",
        "rec = recall_score(all_labels, all_preds, average='weighted')\n",
        "err_rate = 1 - acc\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall:\", rec)\n",
        "print(\"Error Rate:\", err_rate)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPd1YliYAMi6",
        "outputId": "eb902776-daaf-48ec-902e-b1ff4ed1d344"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Classes Detected: ['Bacterial leaf blight', 'Bug', 'Dubas', 'Healthy', 'Honey', 'brown spots', 'white scale']\n",
            "Total images: 3848 | Train: 2693 | Val: 769 | Test: 386\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Small_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Small_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Train Loss: 0.6957 | Val Acc: 0.6632\n",
            "Epoch 2/5 | Train Loss: 0.3124 | Val Acc: 0.8010\n",
            "Epoch 3/5 | Train Loss: 0.2877 | Val Acc: 0.8166\n",
            "Epoch 4/5 | Train Loss: 0.2134 | Val Acc: 0.8153\n",
            "Epoch 5/5 | Train Loss: 0.1237 | Val Acc: 0.8349\n",
            "Training complete. Best Val Acc: 0.834850455136541\n",
            "Accuracy: 0.8238341968911918\n",
            "F1 Score: 0.8164955426864442\n",
            "Precision: 0.8225794419459602\n",
            "Recall: 0.8238341968911918\n",
            "Error Rate: 0.17616580310880825\n",
            "Confusion Matrix:\n",
            " [[ 1  2  0  2  0  0  0]\n",
            " [ 0 50  5  4  2  1  1]\n",
            " [ 0  9 50  1 10  0  0]\n",
            " [ 0  0  1 82  0  0  0]\n",
            " [ 0  9 13  2 21  0  0]\n",
            " [ 0  0  0  0  0 22  0]\n",
            " [ 0  0  0  6  0  0 92]]\n",
            "\n",
            "Classification Report:\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "Bacterial leaf blight       1.00      0.20      0.33         5\n",
            "                  Bug       0.71      0.79      0.75        63\n",
            "                Dubas       0.72      0.71      0.72        70\n",
            "              Healthy       0.85      0.99      0.91        83\n",
            "                Honey       0.64      0.47      0.54        45\n",
            "          brown spots       0.96      1.00      0.98        22\n",
            "          white scale       0.99      0.94      0.96        98\n",
            "\n",
            "             accuracy                           0.82       386\n",
            "            macro avg       0.84      0.73      0.74       386\n",
            "         weighted avg       0.82      0.82      0.82       386\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 1️⃣ Imports\n",
        "# =========================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# =========================================\n",
        "# 2️⃣ Dataset Setup\n",
        "# =========================================\n",
        "src_dir = \"/content/drive/MyDrive/PALM Reserch/Palm Leaves Dataset\"\n",
        "data_dir = \"/tmp/palm_dataset\"\n",
        "if not os.path.exists(data_dir):\n",
        "    shutil.copytree(src_dir, data_dir)\n",
        "\n",
        "# Filter out empty folders\n",
        "valid_folders = [f for f in os.listdir(data_dir)\n",
        "                 if os.path.isdir(os.path.join(data_dir,f))\n",
        "                 and len(os.listdir(os.path.join(data_dir,f))) > 0]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96,96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "classes = dataset.classes\n",
        "print(\"✅ Classes Detected:\", classes)\n",
        "\n",
        "# Split 70/20/10\n",
        "total_len = len(dataset)\n",
        "train_len = int(0.7 * total_len)\n",
        "val_len = int(0.2 * total_len)\n",
        "test_len = total_len - train_len - val_len\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_len, val_len, test_len])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# =========================================\n",
        "# 3️⃣ Model Setup\n",
        "# =========================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = models.mobilenet_v3_small(pretrained=True)\n",
        "from torchvision.models import MobileNet_V3_Small_Weights\n",
        "weights = MobileNet_V3_Small_Weights.IMAGENET1K_V1  # or DEFAULT for latest weights\n",
        "model = models.mobilenet_v3_small(weights=weights)\n",
        "\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, len(classes))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# scaler = torch.cuda.amp.GradScaler()  # Mixed precision\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# =========================================\n",
        "# 4️⃣ Training Function\n",
        "# =========================================\n",
        "def train_model(model, train_loader, val_loader, epochs=5):\n",
        "    best_val_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        # ---- Training ----\n",
        "        model.train()\n",
        "        running_loss = 0\n",
        "        running_corrects = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "            total_samples += images.size(0)\n",
        "\n",
        "        train_loss = running_loss / total_samples\n",
        "        train_acc = running_corrects / total_samples\n",
        "\n",
        "        # ---- Validation ----\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_corrects = 0\n",
        "        val_samples = 0\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * images.size(0)\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_corrects += torch.sum(preds == labels).item()\n",
        "                val_samples += images.size(0)\n",
        "\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        val_loss /= val_samples\n",
        "        val_acc = val_corrects / val_samples\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), \"best_model.pth\")\n",
        "    print(\"Training complete. Best Val Acc:\", best_val_acc)\n",
        "\n",
        "# =========================================\n",
        "# 5️⃣ Train\n",
        "# =========================================\n",
        "train_model(model, train_loader, val_loader, epochs=5)\n",
        "\n",
        "# =========================================\n",
        "# 6️⃣ Evaluate on Test Set\n",
        "# =========================================\n",
        "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "all_preds, all_labels = [], []\n",
        "test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_loss += loss.item() * images.size(0)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "test_loss /= len(test_dataset)\n",
        "test_acc = accuracy_score(all_labels, all_preds)\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "prec = precision_score(all_labels, all_preds, average='weighted')\n",
        "rec = recall_score(all_labels, all_preds, average='weighted')\n",
        "err_rate = 1 - test_acc\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "print(\"\\n✅ Test Results\")\n",
        "print(\"Loss:\", test_loss)\n",
        "print(\"Accuracy:\", test_acc)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"Precision:\", prec)\n",
        "print(\"Recall:\", rec)\n",
        "print(\"Error Rate:\", err_rate)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(all_labels, all_preds, target_names=classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "_wr_toz7KZC0",
        "outputId": "700b6050-7a1b-4f53-a528-f17875177406"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Classes Detected: ['Bacterial leaf blight', 'Bug', 'Dubas', 'Healthy', 'Honey', 'brown spots', 'white scale']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1893577650.py:82: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(device_type=\"cuda\"):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "autocast.__init__() got an unexpected keyword argument 'device_type'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1893577650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# 5️⃣ Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;31m# =========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m# =========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1893577650.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, epochs)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/typing_extensions.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m                 \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2956\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoroutines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutinefunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: autocast.__init__() got an unexpected keyword argument 'device_type'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-LLM Setup"
      ],
      "metadata": {
        "id": "Dfy2FAPNT8m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "jK1Gal0zP49Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# 1️⃣ Imports\n",
        "# =========================================\n",
        "import torch\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
        "from functools import lru_cache\n",
        "\n",
        "# =========================================\n",
        "# 2️⃣ Device\n",
        "# =========================================\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# =========================================\n",
        "# 3️⃣ Load DL model (MobileNetV3) for classification\n",
        "# =========================================\n",
        "classes = [\"Bacterial leaf blight\", \"Bug\", \"Dubas\", \"Healthy\", \"Honey\", \"brown spots\", \"white scale\"]\n",
        "\n",
        "weights = models.MobileNet_V3_Small_Weights.IMAGENET1K_V1\n",
        "dl_model = models.mobilenet_v3_small(weights=weights)\n",
        "dl_model.classifier[3] = torch.nn.Linear(dl_model.classifier[3].in_features, len(classes))\n",
        "\n",
        "# تأكد من وضع مسار best_model.pth الصحيح\n",
        "dl_model.load_state_dict(torch.load(\"best_model.pth\", map_location=device))\n",
        "dl_model = dl_model.to(device)\n",
        "dl_model.eval()\n",
        "\n",
        "# =========================================\n",
        "# 4️⃣ Image transform\n",
        "# =========================================\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96, 96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# =========================================\n",
        "# 5️⃣ Load LLM (small) on CPU\n",
        "# =========================================\n",
        "llm_model_name = \"google/flan-t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(llm_model_name)\n",
        "llm_model = AutoModelForSeq2SeqLM.from_pretrained(llm_model_name)\n",
        "llm_gen = pipeline(\"text2text-generation\", model=llm_model, tokenizer=tokenizer, device=-1)\n",
        "\n",
        "# =========================================\n",
        "# 6️⃣ Fallback templates\n",
        "# =========================================\n",
        "FALLBACK_SNIPPETS = {\n",
        "    \"Bacterial leaf blight\": {\"symptoms\":\"Watery spots on leaves turning brown.\",\"causes\":\"Bacterial infection.\",\"treatment\":\"Remove infected leaves, apply copper sprays.\"},\n",
        "    \"Dubas\": {\"symptoms\":\"Yellowing leaves with sticky honeydew.\",\"causes\":\"Dubas bug feeding on sap.\",\"treatment\":\"Sprays, remove weeds, sticky traps.\"},\n",
        "    \"Bug\": {\"symptoms\":\"Chewing or yellowing damage.\",\"causes\":\"Insect pests.\",\"treatment\":\"Field scouting, traps, pesticide if needed.\"},\n",
        "    \"white scale\": {\"symptoms\":\"White scales on fronds.\",\"causes\":\"Scale insects sucking sap.\",\"treatment\":\"Prune infested fronds, mineral oil sprays.\"},\n",
        "    \"brown spots\": {\"symptoms\":\"Brown spots on fronds.\",\"causes\":\"Fungal infection.\",\"treatment\":\"Prune infected fronds, apply fungicide.\"},\n",
        "    \"Honey\": {\"symptoms\":\"Sticky honeydew on fronds.\",\"causes\":\"Insect secretions.\",\"treatment\":\"Control insects, wash leaves.\"},\n",
        "    \"Healthy\": {\"symptoms\":\"Green, healthy fronds.\",\"causes\":\"No disease.\",\"treatment\":\"Maintain normal care.\"}\n",
        "}\n",
        "\n",
        "# =========================================\n",
        "# 7️⃣ LLM Description Function\n",
        "# =========================================\n",
        "PROMPT_TEMPLATE = \"\"\"You are an expert agronomist for date palm diseases.\n",
        "Write a short description for \"{disease}\" with exactly three sections:\n",
        "\n",
        "Symptoms: 1-2 sentences\n",
        "Causes: 1-2 sentences\n",
        "Treatment: 1-2 sentences\n",
        "\n",
        "Keep it simple for farmers and avoid repeating phrases.\n",
        "\"\"\"\n",
        "\n",
        "def clean_text(text):\n",
        "    # إزالة التكرار\n",
        "    words = text.split()\n",
        "    seen = set()\n",
        "    result = []\n",
        "    for w in words:\n",
        "        if w.lower() not in seen:\n",
        "            result.append(w)\n",
        "            seen.add(w.lower())\n",
        "    return \" \".join(result)\n",
        "\n",
        "@lru_cache(maxsize=128)\n",
        "def get_llm_description(disease_name):\n",
        "    try:\n",
        "        prompt = PROMPT_TEMPLATE.format(disease=disease_name)\n",
        "        out = llm_gen(prompt, max_new_tokens=150, do_sample=False)[0]['generated_text']\n",
        "        out_clean = clean_text(out)\n",
        "        # fallback if output empty\n",
        "        if not out_clean.strip():\n",
        "            snippet = FALLBACK_SNIPPETS.get(disease_name, FALLBACK_SNIPPETS[\"Bug\"])\n",
        "            out_clean = f\"Symptoms: {snippet['symptoms']}\\nCauses: {snippet['causes']}\\nTreatment: {snippet['treatment']}\"\n",
        "        return out_clean\n",
        "    except:\n",
        "        snippet = FALLBACK_SNIPPETS.get(disease_name, FALLBACK_SNIPPETS[\"Bug\"])\n",
        "        return f\"Symptoms: {snippet['symptoms']}\\nCauses: {snippet['causes']}\\nTreatment: {snippet['treatment']}\"\n",
        "\n",
        "# =========================================\n",
        "# 8️⃣ Predict function\n",
        "# =========================================\n",
        "def predict_image(img_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    x = transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = dl_model(x)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        conf, idx = torch.max(probs, dim=1)\n",
        "        label = classes[idx.item()]\n",
        "    description = get_llm_description(label)\n",
        "    return {\"label\": label, \"confidence\": conf.item(), \"description\": description}\n",
        "\n",
        "# =========================================\n",
        "# 9️⃣ Example usage\n",
        "# =========================================\n",
        "if __name__ == \"__main__\":\n",
        "    img_path = \"/content/drive/MyDrive/PALM Reserch/Palm Leaves Dataset/Bacterial leaf blight/DSC_0365.JPG\"\n",
        "    result = predict_image(img_path)\n",
        "    print(f\"Diagnosis: {result['label']} | Confidence: {result['confidence']:.2f}\")\n",
        "    print(\"Description:\\n\", result[\"description\"])\n"
      ],
      "metadata": {
        "id": "SmwXLH3bTgBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wc1759euXciU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}